#  突破！首次利用大模型在真实环境发现十余个零日漏洞   
安全内参  奇安信集团   2024-10-22 20:04  
  
## 静态代码分析工具Vulnhuntr利用Claude AI识别零日漏洞，并推测漏洞利用代码。  
  
  
  
安全内参10月21日消息，美国AI安全厂商Protect AI的研究人员推出了一款免费开源的工具  
Vulnhuntr  
。  
  
![](https://mmbiz.qpic.cn/sz_mmbiz_png/FzZb53e8g7sYu3Jia4fAou2jwcoKsYLk4pGA7XShVdgwzaFqoDGhPByfbFsq8HDiaWJA5mmT7rZyg2VPC0TKw2hg/640?wx_fmt=png&from=appmsg "")  
  
  
借助Anthropic的Claude AI模型，该工具能够在Python代码库中发现零日漏洞。  
  
  
**自动遍历用户输入环节代码，**  
  
****  
**分析完整调用链**  
  
Protect AI的首席AI威胁研究员Dan McInerney与同事Marcello Salvati共同开发了这款工具。他解释道：“这款工具不仅仅是简单地粘贴一些代码让其分析，它会自动寻找那些可能处理远程用户输入的项目文件。随后，Claude会分析这些文件中的潜在漏洞。对于每个潜在的漏洞，Claude会接收一个高度优化的提示，进入循环分析。”  
  
“在这个循环中，Claude会智能地不断请求代码中的其他函数、类或变量，直到完整分析用户输入到服务器输出的整个调用链为止，同时不会超出其上下文窗口的限制。与现有的静态代码分析器相比，它的优势在于能够大幅减少误报和漏报，因为它可以读取完整的调用链，而不仅仅是一次处理小段代码。”   
  
![](https://mmbiz.qpic.cn/sz_mmbiz_png/FzZb53e8g7sYu3Jia4fAou2jwcoKsYLk4GUmVPHP6sadFrall2kshtGUhdFp24suHdmh7sdCxaKJu34LBoDgRyg/640?wx_fmt=png&from=appmsg "")  
  
图：Vulnhuntr工作流程  
  
McInerney表示，这种方法能够揭示复杂的多步骤漏洞，而不仅仅是标记出像eval()这样的已知危险函数。    
  
McInerney指出：“该工具最初是为Claude设计的，充分利用了Claude在提示工程中的最佳实践，因此在使用Claude时效果最佳。我们也增加了使用[OpenAI的] GPT-4的选项，并测试了GPT-4o模型，但效果不佳。不过，修改提示以适应GPT-4o模型非常简单，只需修改一行代码。通过开源这款工具，我们希望在新模型推出时，能够鼓励类似的修改。”  
  
  
**目前已发现十几个零日漏洞**  
  
截至目前，McInerney表示，Vulnhuntr已经在多个大型开源Python项目中发现了十几个零日漏洞。  
  
他补充道：“这些漏洞此前从未被发现，也未向项目维护者报告。”  
  
该工具目前专注于七种可远程利用的漏洞类型：  
- 任意文件覆盖（AFO）  
  
- 本地文件包含（LFI）  
  
- 服务器端请求伪造（SSRF）  
  
- 跨站脚本攻击（XSS）  
  
- 不安全的直接对象引用（IDOR）  
  
- SQL注入（SQLi）  
  
- 远程代码执行（RCE）  
  
受影响的项目包括：  
- gpt_academic，GitHub上有64k星标，发现LFI和XSS漏洞  
  
- ComfyUI，50K星标，发现XSS漏洞  
  
- FastChat，35K星标，发现SSRF漏洞  
  
- Ragflow，16K星标，发现RCE漏洞  
  
其他在不到90天前被发现存在漏洞的项目尚未公开，以便项目维护者有时间修复问题。  
  
McInerney透露，目前唯一已经修复其发现漏洞的项目是Ragflow。  
  
  
**该项目仍存在局限性**  
  
Vulnhuntr也有一些局限性。**它目前仅适用于Python代码，并依赖Python静态分析器**。因此，当扫描包含其他语言代码（例如TypeScript）的Python项目时，误报的可能性会增加。  
  
在生成漏洞利用概念验证（PoC）时，软件会生成一个置信分数，范围从1到10。得分为7表示可能是一个有效漏洞，但PoC代码可能还需优化；得分为8或更高则表示漏洞很可能有效；而得分为6或以下的漏洞则不太可能有效。  
  
输出结果示例如下所示：  
```
scratchpad: 
1. Analyzing the add_llm function in llm_app.py.
2. Identified user input used as keys to access dictionaries: EmbeddingModel, ChatModel, RerankModel, CvModel, and TTSModel.
3. These dictionaries contain class references, which are instantiated with user-supplied parameters.
4. The factory variable is directly used from user input (req['llm_factory']) without proper validation. [...]
---------------------------------------- 
analysis: 
The add_llm function in llm_app.py contains a critical Remote Code Execution (RCE) vulnerability. The function uses user-supplied input (req['llm_factory'] and req['llm_name']) to dynamically instantiate classes from the EmbeddingModel, ChatModel, RerankModel, CvModel, and TTSModel dictionaries. This pattern of using user input as a key to access and instantiate classes is inherently dangerous, as it allows an attacker to potentially execute arbitrary code. The vulnerability is exacerbated by the lack of comprehensive input validation or sanitization on these user-supplied values. [...]
---------------------------------------- 
poc: 
POST /add_llm HTTP/1.1 
Host: target.com 
Content-Type: application/json 
Authorization: Bearer <valid_token> 

{ "llm_factory": "__import__('os').system", "llm_name": "id", "model_type": "EMBEDDING", "api_key": "dummy_key"}
---------------------------------------- 
confidence_score: 8 
---------------------------------------- 
vulnerability_types:
  - RCE 
----------------------------------------
```  
  
另一个挑战是，**大模型（LLM）并不具备确定性。同一提示词在不同时间可能会生成不同结果，因此有时需要多次运行分析**。尽管如此，McInerney认为，Vulnhuntr相比现有的静态分析器仍有显著的优势  
。  
  
此外，由于Claude API并非免费使用，因此**也涉及一些成本问题**。  
  
McInerney说：“我一般这样使用这款工具，先识别项目中处理远程用户输入的一两个文件，然后告诉工具只分析这些文件。以这种方式使用时，平均的代币使用成本不到0.50美元。如果让工具自动寻找与网络相关的文件，它通常会扫描10到20个文件，而不是最佳的1到2个文件。根据项目规模，扫描所有与网络相关的文件的成本通常在1到3美元之间。”  
  
  
**首次利用大模型**  
  
****  
**在真实环境发现零日漏洞**  
  
McInerney相信，Vulnhuntr的发现代表了AI辅助工具首次在公开项目中实际发现零日漏洞。  
  
他指出：“有很多论文声称AI可以发现零日漏洞，但这些声明往往具有误导性，因为他们的AI只是被输入了已知漏洞的目标代码，或者使用了未经过训练的代码，然后宣称AI成功发现了零日漏洞。据我们所知，Vulnhuntr的发布标志着大模型首次在实际环境中发现零日漏洞。”  
  
他举例提到了一篇[学术论文](http://mp.weixin.qq.com/s?__biz=MzI4NDY2MDMwMw==&mid=2247511975&idx=2&sn=51c504be3959e1bf389ceda027ef2111&chksm=ebfae887dc8d61914e1e857ef1e3658bde3c982533b4162ef246707d30c9fab3d656a79123bb&scene=21#wechat_redirect)  
，伊利诺伊大学厄巴纳-香槟分校计算机科学助理教授Daniel Kang是该论文的合著者之一。他向外媒The Register解释道，依赖模拟数据是安全研究中的常见做法。  
  
Kang表示：“在安全研究中，广泛接受的做法是将真实环境的模拟视为现实世界的合理代理。我可以提供数百篇安全领域的论文和新闻稿，展示在模拟环境中或使用过去的真实漏洞进行工具测试的案例，没有人质疑这些结果的有效性。准确的说法是我们模拟了零日环境，这已经成为公认的标准做法。”  
  
Kang的论文描述了使用大模型智能体利用零日漏洞的过程，指出Vulnhuntr并不处理漏洞利用环节。他还表示，在没有对误报进行深入分析或与ZAP、Metasploit或BurpSuite等工具进行对比的情况下，很难评价Vulnhuntr相较于现有开源或商业替代工具的表现。  
  
McInerney补充道，Vulnhuntr发现的漏洞一旦确定，往往非常容易利用。  
  
他说：“该工具在发现漏洞后会生成一个PoC漏洞利用。尽管通常需要对PoC进行一些小的调整才能生效，但在阅读大模型提供的漏洞分析后，如何进行调整就一目了然。”  
  
据了解，Vulnhuntr已在GitHub上发布，感兴趣的读者可以尝试使用。（  
https://github.com/protectai/vulnhuntr）  
  
参考资料：theregister.com  
  
  
