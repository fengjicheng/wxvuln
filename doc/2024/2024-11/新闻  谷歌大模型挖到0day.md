#  新闻 | 谷歌大模型挖到0day   
原创 4°  励行安全   2024-11-05 20:30  
  
![](https://mmbiz.qpic.cn/mmbiz_png/UN9bb0CZZJPaqibGOoBicqQ3fhoicNvvJwiaC3dnkelEWzicsibdhUgRgAXPd8DDdvOPd1QxFFWd7uibsm2icZ6ku15FVA/640?wx_fmt=png&from=appmsg "")  
  
谷歌的 Big Sleep AI 在 SQLite 开源数据库引擎中发现了一个零日漏洞。  
  
发现该漏洞的“Big Sleep”AI模型属Google Project Zero 和 Google DeepMind 之间的合作项目，旨在大型语言模型的辅助下进行漏洞研究。  
  
在“Big Sleep”中，研究人员利用 LLM 的代码理解和推理能力，在识别和演示安全漏洞时利用 AI 代理来模拟人类行为，其中需要使用一套专用工具来允许代理浏览目标代码库，并在沙盒环境中运行 Python 脚本以生成用于模糊测试的输入、调试程序并观察结果。  
  
**笔者分析**  
  
大模型在代码审计中的应用一定会越来越广，还是我之前的观点。白盒审计相较于黑盒测试更适合大模型，目前最为成熟的大模型其实是大语言模型，顾名思义，它擅长的是对语义的理解、分析、推理。而黑盒测试，比如渗透测试，非常发散、逻辑链条非常多，更多的是一种基于经验的思路跳转，比如看到登录框想到弱口令、sql注入等。这在人的思维中常见是因为我们学习了这些技能知识，但对于大语言模型来说，它由于moderation的原因可能在原始训练数据中就没有这类信息，通过后天微调的方式来让他学习的效果一般都不太好，并且黑盒测试的体系过于庞杂，并不是一项专一能力，目前的LLM难以胜任。  
  
而代码审计则不同，这本身就是对于语义的理解，在大模型擅长的范围内（相较于黑盒测试而言），并且对于静态分析而言，并不需要其他过多的能力，更多的是关注上下文的一些逻辑，这是大模型会的，因此在这个方面大模型更有优势。这也是近些年AI辅助代码审计逐渐有了新的项目与产品，而基于大模型的自动化渗透测试系统迟迟没有开发出来的原因。  
  
