#  Ollama AI 框架中的严重漏洞可能导致 DoS、模型盗窃和模型中毒   
Rhinoer  犀牛安全   2024-11-21 16:00  
  
![](https://mmbiz.qpic.cn/mmbiz_png/qvpgicaewUBkuvNbGW25YicDwvtlp0HUvOz6ic5M2HP2OTJTEFVKKgpcYgKQM3OQqiax5fnejthqku5VibqvSW0SIoA/640?wx_fmt=png&from=appmsg "")  
  
网络安全研究人员披露了 Ollama 人工智能 (AI) 框架中的六个安全漏洞，恶意行为者可以利用这些漏洞执行各种操作，包括拒绝服务、模型中毒和模型盗窃。  
  
Oligo Security 研究员 Avi Lumelsky 在上周发布的一份报告中表示：“总的来说，这些漏洞可能允许攻击者通过单个 HTTP 请求执行各种恶意操作，包括拒绝服务 (DoS) 攻击、模型中毒、模型盗窃等。”  
  
Ollama 是一款开源应用程序，允许用户在 Windows、Linux 和 macOS 设备上本地部署和操作大型语言模型 (LLM)。迄今为止，其在 GitHub 上的项目存储库已被分叉 7,600 次。  
  
这六个漏洞的简要描述如下：  
- CVE-2024-39719（CVSS 评分：7.5） - 攻击者可利用 /api/create 端点来确定服务器中文件是否存在的漏洞（已在 0.1.47 版中修复）  
  
- CVE-2024-39720（CVSS 评分：8.2） - 一种越界读取漏洞，可能通过 /api/create 端点导致应用程序崩溃，从而导致 DoS 情况（已在 0.1.46 版中修复）  
  
- CVE-2024-39721（CVSS 评分：7.5） - 当传递文件“/dev/random”作为输入并反复调用 /api/create 端点时，此漏洞会导致资源耗尽并最终导致 DoS（已在 0.1.34 版中修复）  
  
- CVE-2024-39722（CVSS 评分：7.5） - api/push 端点中的路径遍历漏洞，可暴露服务器上现有的文件以及部署 Ollama 的整个目录结构（已在 0.1.46 版中修复）  
  
- 存在一个漏洞，可能通过来自不受信任来源的 /api/pull 端点导致模型中毒（无 CVE 标识符，未修补）  
  
- 存在一个漏洞，可能导致模型通过 /api/push 端点被窃取到不受信任的目标（无 CVE 标识符，未修补）  
  
对于这两个未解决的漏洞，Ollama 的维护人员建议用户通过代理或 Web 应用程序防火墙过滤哪些端点暴露给互联网。  
这意味着默认情况下，并非所有端点都应暴露。  
  
Lumelsky 说：“这是一个危险的假设。并不是每个人都知道这一点，或者过滤到 Ollama 的 HTTP 路由。目前，这些端点可通过 Ollama 的默认端口作为每次部署的一部分使用，没有任何分离或文档来支持它。”  
  
Oligo 表示，它发现了 9,831 个运行 Ollama 的面向互联网的独特实例，其中大多数位于中国、美国、德国、韩国、台湾、法国、英国、印度、新加坡和香港。四分之一面向互联网的服务器被认为容易受到已发现的漏洞的影响。  
  
四个多月前，云安全公司 Wiz 披露了一个影响 Ollama 的严重漏洞 ( CVE-2024-37032 )，该漏洞可能被利用来实现远程代码执行。  
  
Lumelsky 指出：“未经授权将 Ollama 暴露到互联网相当于将 Docker 套接字暴露到公共互联网，因为它可以上传文件并具有模型拉取和推送功能（可能被攻击者滥用）。”  
  
  
信息来源：  
The Hacker News  
  
